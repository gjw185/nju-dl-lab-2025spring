# 实验二：神经网络基础：激活函数与正则化

## 开始之前

我们在本次实验中使用Jupyter Notebook进行实验，请参考[Jupyter Notebook使用](../lab1/环境配置指南.md#jupyter-notebook)，按照文档中详细步骤进行操作，完成Jupyter Notebook的配置。

## 实验任务
本次实验分为两个任务：MINIST手写数字识别（约60分钟）和正则化和激活函数探索（约90分钟）。

### [任务一：MINIST手写数字识别](./MINIST手写数字识别.md)
[下载任务一代码](https://cdn.jsdelivr.net/gh/zhiweinju/nju-dl-lab-2025spring@main/docs/lab2/lab2_p1.ipynb){ .md-button}

在这个任务中，你将：

1. 实现一个简单的感知机和多层感知机模型
2. 使用MNIST数据集进行手写数字识别
3. 掌握神经网络的基本概念和训练过程

主要内容包括：

- 感知机的基本原理和局限性
- 多层感知机的从零实现
- 使用PyTorch框架实现多层感知机
- 模型训练与评估
- 思考题讨论

通过本任务，你将掌握神经网络的基础知识，并能够使用PyTorch框架构建和训练简单的神经网络模型。


### [任务二：正则化和激活函数探索](./正则化和激活函数探索.md)
[下载任务二代码](https://cdn.jsdelivr.net/gh/zhiweinju/nju-dl-lab-2025spring@main/docs/lab2/lab2_p2.ipynb){ .md-button}

在这个任务中，你将探索神经网络中的两个重要组成部分：激活函数和正则化方法。

主要内容包括：

1. 激活函数实验
   
    - 实现并可视化常见激活函数(ReLU、Sigmoid、Tanh)及其导数
    - 分析不同激活函数的特性和适用场景
    - 探索梯度消失问题
    - ReLU死亡现象研究

2. 正则化方法实验
   
    - L2正则化的实现与效果分析
    - Dropout正则化的原理与实践
    - 对比不同正则化方法的效果
    - 分析正则化对模型泛化能力的影响

通过本任务，你将深入理解激活函数和正则化在神经网络中的作用，掌握防止过拟合的技巧，并能够根据实际问题选择合适的激活函数和正则化方法。

## 实验提交
实验完成后，请提交以下材料：

1. 运行成功的Jupyter Notebook文件
2. 一份PDF报告，报告内容**包括但不限于**：
    1. [实验一提交内容](../lab1/实验一介绍.md#_3)
    2. 实验二思考题答案
    3. 实验心得与体会

## 提交说明

1. 本次提交的内容为: 实验一和实验二要求提交的内容，具体要求请参见实验网站（https://zhiweinju.github.io/nju-dl-lab-2025spring/）
2. 提交的报告文件请以PDF文件格式上传到selearning网站，上传文件的文件命名格式为: 学号_姓名_报告一.pdf，比如：123456789_张三_报告一.pdf
3. 其他提交文件（如 运行成功的Jupyter Notebook文件），请加上前缀: 学号_姓名_，比如: 123456789_张三_lab1.ipynb
4. 本次提交的截止时间为 3月7日23:59:59
5. 对于迟交的处理: 迟交一周以内，折扣系数为0.8，迟交超过一周，折扣系数为0.6，超过一个月停止接收提交，尚未提交者本次作业计0分